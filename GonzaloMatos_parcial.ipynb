{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7cd0a7",
   "metadata": {},
   "source": [
    "# Parcial 1 Parte Práctica: Aplicación de DNN en clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295c8a5",
   "metadata": {},
   "source": [
    "Genere una red neuronal con Keras para pronosticar los valores binarios de un set de datos.\n",
    "\n",
    "* Usar para entrenar y evaluar el dataset: Aprendizaje_breast-cancer-wisconsin.tab\n",
    "\n",
    "* Usar para pronosticar: X_para_evaluar.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea65acc",
   "metadata": {},
   "source": [
    "## Sobre los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cee14b",
   "metadata": {},
   "source": [
    "El que dice: __Aprendizaje_breast-cancer-wisconsin.tab__ es el que tienen que usar para entrenar y elegir la mejor red neuronal que puedan. \n",
    "\n",
    "Es un problema real, es un trabajo hecho en imágenes sobre tumores, estos son elementos medidos, así que debería andar muy bien. \n",
    "\n",
    "Cuando lo abran hay una columna que se llama type, si es maligno o beningo, es un resultado binario y es la columna a pronosticar con el modelo.\n",
    "\n",
    "Hay una columna que no sirve para nada que se llama selective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b5384",
   "metadata": {},
   "source": [
    "## Se pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87d1d3",
   "metadata": {},
   "source": [
    "1) Deberá crear un notebook para generar un modelo de producción con redes neuronales entrenado con los datos entiquetados y que permita hacer luego, el pronóstico para los datos indicados en el archivo __X_para_evaluar.csv__\n",
    "* La métrica usada será Accuracy\n",
    "* La arquitectura es libre. Pueden probar diferentes números de capas, neuronas y funciones de activación.\n",
    "* Todas las divisiones de los datos son: 75% 25%\n",
    "\n",
    "__Nota:__ para que Keras les tome la variable Type la tienen que pasar como valores 0 y 1. Yo voy a elegir 0 para maligno y 1 para benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c520a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84eddfb7",
   "metadata": {},
   "source": [
    "2) Deberán generar un csv con una única columna ypred con los valores pronosticados de type. Cuando creen ese csv, pónganlo sin índce, o sea, que tenga una sola columna, si lo hacen desde pandas por ejemplo, usar la opción index=false, para que no agregue la columna índice.\n",
    "\n",
    "* El archivo deberá tener por nombre, su nombre \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357a8d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1040/528586102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#importamos librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import initializers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c581af71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump thickness</th>\n",
       "      <th>Unif_Cell_Size</th>\n",
       "      <th>Unif_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatine</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>type</th>\n",
       "      <th>Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.67</td>\n",
       "      <td>9.96</td>\n",
       "      <td>9.27</td>\n",
       "      <td>2.40</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>malign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>benign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>benign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.29</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.11</td>\n",
       "      <td>malign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.64</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.48</td>\n",
       "      <td>9.86</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.73</td>\n",
       "      <td>malign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.29</td>\n",
       "      <td>2.63</td>\n",
       "      <td>9.22</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.13</td>\n",
       "      <td>malign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>4.66</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.07</td>\n",
       "      <td>9.36</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>malign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.94</td>\n",
       "      <td>benign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>4.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>benign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>6.08</td>\n",
       "      <td>4.91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.16</td>\n",
       "      <td>3.83</td>\n",
       "      <td>9.20</td>\n",
       "      <td>2.59</td>\n",
       "      <td>malign</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump thickness  Unif_Cell_Size  Unif_Cell_Shape  Marginal_Adhesion  \\\n",
       "0               9.67            9.96             9.27               2.40   \n",
       "1               0.14            0.15             0.47               0.82   \n",
       "2               0.61            0.49             0.99               0.19   \n",
       "3               7.29            1.11             3.42               0.07   \n",
       "4               6.03            2.47             1.64               9.15   \n",
       "..               ...             ...              ...                ...   \n",
       "578             5.00            4.92             4.65               5.29   \n",
       "579             4.66            1.91             2.22               0.28   \n",
       "580             2.90            0.77             0.24               3.74   \n",
       "581             4.72            0.04             0.46               2.62   \n",
       "582             6.08            4.91             9.90               9.48   \n",
       "\n",
       "     Single_Cell_Size  Bare_Nuclei  Bland_Chromatine  Normal_Nucleoli  \\\n",
       "0                9.49         7.93              7.90             0.33   \n",
       "1                1.71         0.19              2.22             0.55   \n",
       "2                1.98         0.27              2.07             0.71   \n",
       "3                4.63         0.25              4.17             3.76   \n",
       "4                4.48         9.86              4.43             3.58   \n",
       "..                ...          ...               ...              ...   \n",
       "578              2.63         9.22              2.81             0.78   \n",
       "579              5.07         9.36              4.67             0.76   \n",
       "580              2.32         0.23              1.19             1.12   \n",
       "581              1.39         0.50              0.70             0.86   \n",
       "582              9.48         9.16              3.83             9.20   \n",
       "\n",
       "     Mitoses    type Selected  \n",
       "0       0.06  malign       No  \n",
       "1       0.49  benign       No  \n",
       "2       0.28  benign       No  \n",
       "3       3.11  malign       No  \n",
       "4       3.73  malign       No  \n",
       "..       ...     ...      ...  \n",
       "578     0.13  malign       No  \n",
       "579     0.90  malign       No  \n",
       "580     0.94  benign       No  \n",
       "581     0.92  benign       No  \n",
       "582     2.59  malign       No  \n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creamos el dataset\n",
    "df = pd.read_csv('Aprendizaje_breast-cancer-wisconsin.tab',sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d26e5831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump thickness</th>\n",
       "      <th>Unif_Cell_Size</th>\n",
       "      <th>Unif_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatine</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>type</th>\n",
       "      <th>Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.67</td>\n",
       "      <td>9.96</td>\n",
       "      <td>9.27</td>\n",
       "      <td>2.40</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.29</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.64</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.48</td>\n",
       "      <td>9.86</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.29</td>\n",
       "      <td>2.63</td>\n",
       "      <td>9.22</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>4.66</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.07</td>\n",
       "      <td>9.36</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>4.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>6.08</td>\n",
       "      <td>4.91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.16</td>\n",
       "      <td>3.83</td>\n",
       "      <td>9.20</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump thickness  Unif_Cell_Size  Unif_Cell_Shape  Marginal_Adhesion  \\\n",
       "0               9.67            9.96             9.27               2.40   \n",
       "1               0.14            0.15             0.47               0.82   \n",
       "2               0.61            0.49             0.99               0.19   \n",
       "3               7.29            1.11             3.42               0.07   \n",
       "4               6.03            2.47             1.64               9.15   \n",
       "..               ...             ...              ...                ...   \n",
       "578             5.00            4.92             4.65               5.29   \n",
       "579             4.66            1.91             2.22               0.28   \n",
       "580             2.90            0.77             0.24               3.74   \n",
       "581             4.72            0.04             0.46               2.62   \n",
       "582             6.08            4.91             9.90               9.48   \n",
       "\n",
       "     Single_Cell_Size  Bare_Nuclei  Bland_Chromatine  Normal_Nucleoli  \\\n",
       "0                9.49         7.93              7.90             0.33   \n",
       "1                1.71         0.19              2.22             0.55   \n",
       "2                1.98         0.27              2.07             0.71   \n",
       "3                4.63         0.25              4.17             3.76   \n",
       "4                4.48         9.86              4.43             3.58   \n",
       "..                ...          ...               ...              ...   \n",
       "578              2.63         9.22              2.81             0.78   \n",
       "579              5.07         9.36              4.67             0.76   \n",
       "580              2.32         0.23              1.19             1.12   \n",
       "581              1.39         0.50              0.70             0.86   \n",
       "582              9.48         9.16              3.83             9.20   \n",
       "\n",
       "     Mitoses  type Selected  \n",
       "0       0.06     0       No  \n",
       "1       0.49     1       No  \n",
       "2       0.28     1       No  \n",
       "3       3.11     0       No  \n",
       "4       3.73     0       No  \n",
       "..       ...   ...      ...  \n",
       "578     0.13     0       No  \n",
       "579     0.90     0       No  \n",
       "580     0.94     1       No  \n",
       "581     0.92     1       No  \n",
       "582     2.59     0       No  \n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reemplazo de valores \n",
    "df['type']= df['type'].replace(['malign','benign'],[0,1])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "36f9186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump thickness</th>\n",
       "      <th>Unif_Cell_Size</th>\n",
       "      <th>Unif_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatine</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.67</td>\n",
       "      <td>9.96</td>\n",
       "      <td>9.27</td>\n",
       "      <td>2.40</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.29</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.64</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.48</td>\n",
       "      <td>9.86</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.29</td>\n",
       "      <td>2.63</td>\n",
       "      <td>9.22</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>4.66</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.07</td>\n",
       "      <td>9.36</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>4.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>6.08</td>\n",
       "      <td>4.91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.16</td>\n",
       "      <td>3.83</td>\n",
       "      <td>9.20</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump thickness  Unif_Cell_Size  Unif_Cell_Shape  Marginal_Adhesion  \\\n",
       "0               9.67            9.96             9.27               2.40   \n",
       "1               0.14            0.15             0.47               0.82   \n",
       "2               0.61            0.49             0.99               0.19   \n",
       "3               7.29            1.11             3.42               0.07   \n",
       "4               6.03            2.47             1.64               9.15   \n",
       "..               ...             ...              ...                ...   \n",
       "578             5.00            4.92             4.65               5.29   \n",
       "579             4.66            1.91             2.22               0.28   \n",
       "580             2.90            0.77             0.24               3.74   \n",
       "581             4.72            0.04             0.46               2.62   \n",
       "582             6.08            4.91             9.90               9.48   \n",
       "\n",
       "     Single_Cell_Size  Bare_Nuclei  Bland_Chromatine  Normal_Nucleoli  \\\n",
       "0                9.49         7.93              7.90             0.33   \n",
       "1                1.71         0.19              2.22             0.55   \n",
       "2                1.98         0.27              2.07             0.71   \n",
       "3                4.63         0.25              4.17             3.76   \n",
       "4                4.48         9.86              4.43             3.58   \n",
       "..                ...          ...               ...              ...   \n",
       "578              2.63         9.22              2.81             0.78   \n",
       "579              5.07         9.36              4.67             0.76   \n",
       "580              2.32         0.23              1.19             1.12   \n",
       "581              1.39         0.50              0.70             0.86   \n",
       "582              9.48         9.16              3.83             9.20   \n",
       "\n",
       "     Mitoses  type  \n",
       "0       0.06     0  \n",
       "1       0.49     1  \n",
       "2       0.28     1  \n",
       "3       3.11     0  \n",
       "4       3.73     0  \n",
       "..       ...   ...  \n",
       "578     0.13     0  \n",
       "579     0.90     0  \n",
       "580     0.94     1  \n",
       "581     0.92     1  \n",
       "582     2.59     0  \n",
       "\n",
       "[583 rows x 10 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dopeo la columna que no se tiene en cuenta para el problema\n",
    "df= df.drop(columns=['Selected'],axis = 1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8bd11a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#division train y test\n",
    "X= df.drop(axis=1, columns= 'type')\n",
    "y= df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fed9f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.25, random_state= 123)\n",
    "X_val_train, X_val_test, y_val_train, y_val_test = train_test_split(X_train, y_train, test_size= 0.25, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "99f0365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 1s 14ms/step - loss: 0.7736 - accuracy: 0.4190\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.5413\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.5564 - accuracy: 0.7095\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.4835 - accuracy: 0.8440\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.4452 - accuracy: 0.8777\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.4074 - accuracy: 0.8991\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.3801 - accuracy: 0.9021\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3576 - accuracy: 0.8960\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.3389 - accuracy: 0.9113\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.3230 - accuracy: 0.9144\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.3090 - accuracy: 0.9174\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.2966 - accuracy: 0.9297\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.2850 - accuracy: 0.9235\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.2772 - accuracy: 0.9174\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.2656 - accuracy: 0.9266\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.2552 - accuracy: 0.9297\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2507 - accuracy: 0.9358\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2456 - accuracy: 0.9358\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2367 - accuracy: 0.9327\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2291 - accuracy: 0.9450\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2238 - accuracy: 0.9419\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2204 - accuracy: 0.9602 0s - loss: 0.2412 - accuracy: \n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2131 - accuracy: 0.9572\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2094 - accuracy: 0.9511\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2033 - accuracy: 0.9602\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1993 - accuracy: 0.9602\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1943 - accuracy: 0.9602\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1932 - accuracy: 0.9572\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.1879 - accuracy: 0.9602\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 0.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb3cc39d0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creacion del modelo y agregado de capaz con funcion relu como activacion \n",
    "modelo = Sequential()\n",
    "modelo.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo.add(Dense(units=13, activation='relu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo.add(Dense(units=12, activation= 'relu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo.fit(X_val_train,y_val_train , epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f92ffdab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 0.7346 - accuracy: 0.4587\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5874 - accuracy: 0.6972\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.5032 - accuracy: 0.8196\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4467 - accuracy: 0.8593\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4066 - accuracy: 0.8838\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.3776 - accuracy: 0.9021\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.3493 - accuracy: 0.9113\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.3298 - accuracy: 0.9144\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.3120 - accuracy: 0.9205\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.2964 - accuracy: 0.9235\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2846 - accuracy: 0.9358\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2727 - accuracy: 0.9297\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2651 - accuracy: 0.9327\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2547 - accuracy: 0.9388\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2469 - accuracy: 0.9388\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2385 - accuracy: 0.9480\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2305 - accuracy: 0.9480\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2257 - accuracy: 0.9480\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2192 - accuracy: 0.9480 0s - loss: 0.2393 - accuracy: \n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.2159 - accuracy: 0.9511\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2076 - accuracy: 0.9541\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2038 - accuracy: 0.9572\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.2018 - accuracy: 0.9511\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.1962 - accuracy: 0.9572\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.1908 - accuracy: 0.9602\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.1848 - accuracy: 0.9633\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 0.9572\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1803 - accuracy: 0.9664\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1747 - accuracy: 0.9602\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1752 - accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb404c640>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo con funcion activacion LeakyRelu \n",
    "modelo1 = Sequential()\n",
    "modelo1.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo1.add(Dense(units=13, activation='LeakyReLU',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo1.add(Dense(units=12, activation= 'LeakyReLU',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo1.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo1.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo1.fit(X_val_train,y_val_train , epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c465701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 0.6493 - accuracy: 0.6055\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.4684 - accuracy: 0.8318\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.3802 - accuracy: 0.8930\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.3227 - accuracy: 0.9144\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2836 - accuracy: 0.9297\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2569 - accuracy: 0.9358\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 0.9388\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2228 - accuracy: 0.9419 0s - loss: 0.2127 - accura\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2069 - accuracy: 0.9511\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.1950 - accuracy: 0.9572\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.1852 - accuracy: 0.9572\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1767 - accuracy: 0.9633 0s - loss: 0.1125 - accuracy\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.1710 - accuracy: 0.9602\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.1656 - accuracy: 0.9633\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.1594 - accuracy: 0.9633\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1562 - accuracy: 0.9664\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1502 - accuracy: 0.9633\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1491 - accuracy: 0.9633\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1436 - accuracy: 0.9633\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1427 - accuracy: 0.9633\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1390 - accuracy: 0.9633\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1350 - accuracy: 0.9664\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1339 - accuracy: 0.9664\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9664\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1284 - accuracy: 0.9725\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1270 - accuracy: 0.9694\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1260 - accuracy: 0.9664\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1242 - accuracy: 0.9633\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.1220 - accuracy: 0.9633\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1175 - accuracy: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb5304a60>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo con funcion activacion ELU\n",
    "modelo2 = Sequential()\n",
    "modelo2.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo2.add(Dense(units=13, activation='ELU',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo2.add(Dense(units=12, activation= 'ELU',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo2.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo2.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo2.fit(X_val_train,y_val_train , epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "906fd263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 13ms/step - loss: 0.6470 - accuracy: 0.5046\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.5562 - accuracy: 0.7064\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4985 - accuracy: 0.8379\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4550 - accuracy: 0.8899 0s - loss: 0.4300 - accuracy: \n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4253 - accuracy: 0.9052\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.3971 - accuracy: 0.9358\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.3741 - accuracy: 0.9388\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.3549 - accuracy: 0.9358\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.9419\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.3231 - accuracy: 0.9450\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 0.9358\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 0.9480\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.2848 - accuracy: 0.9511\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2724 - accuracy: 0.9480\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2631 - accuracy: 0.9541\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.2533 - accuracy: 0.9541\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2465 - accuracy: 0.9541\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 0.9572\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2299 - accuracy: 0.9602\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.2241 - accuracy: 0.9602\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2180 - accuracy: 0.9602\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.2128 - accuracy: 0.9572\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.9572\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1997 - accuracy: 0.9602\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1978 - accuracy: 0.9664\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1926 - accuracy: 0.9572\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1850 - accuracy: 0.9602\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.1822 - accuracy: 0.9572\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1806 - accuracy: 0.9633\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1757 - accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb560f850>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo con funcion activacion swish\n",
    "modelo3 = Sequential()\n",
    "modelo3.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo3.add(Dense(units=13, activation='swish',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo3.add(Dense(units=12, activation= 'swish',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo3.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo3.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo3.fit(X_val_train,y_val_train , epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c4b68775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6316 - accuracy: 0.6623 - val_loss: 0.5136 - val_accuracy: 0.7677\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.3915 - accuracy: 0.8684 - val_loss: 0.3549 - val_accuracy: 0.8788\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3057 - accuracy: 0.8947 - val_loss: 0.2900 - val_accuracy: 0.9293\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.2503 - accuracy: 0.9298 - val_loss: 0.2517 - val_accuracy: 0.9293\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.2204 - accuracy: 0.9298 - val_loss: 0.2367 - val_accuracy: 0.9293\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1997 - accuracy: 0.9518 - val_loss: 0.2114 - val_accuracy: 0.9394\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1818 - accuracy: 0.9605 - val_loss: 0.1884 - val_accuracy: 0.9596\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1722 - accuracy: 0.9474 - val_loss: 0.1869 - val_accuracy: 0.9495\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1627 - accuracy: 0.9649 - val_loss: 0.1731 - val_accuracy: 0.9596\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1574 - accuracy: 0.9605 - val_loss: 0.1652 - val_accuracy: 0.9596\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1484 - accuracy: 0.9561 - val_loss: 0.1601 - val_accuracy: 0.9596\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1391 - accuracy: 0.9693 - val_loss: 0.1739 - val_accuracy: 0.9394\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1402 - accuracy: 0.9825 - val_loss: 0.1501 - val_accuracy: 0.9596\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1328 - accuracy: 0.9649 - val_loss: 0.1471 - val_accuracy: 0.9596\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1292 - accuracy: 0.9693 - val_loss: 0.1419 - val_accuracy: 0.9596\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1266 - accuracy: 0.9693 - val_loss: 0.1426 - val_accuracy: 0.9596\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1238 - accuracy: 0.9737 - val_loss: 0.1508 - val_accuracy: 0.9394\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1226 - accuracy: 0.9825 - val_loss: 0.1315 - val_accuracy: 0.9596\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1226 - accuracy: 0.9649 - val_loss: 0.1284 - val_accuracy: 0.9596\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1206 - accuracy: 0.9605 - val_loss: 0.1278 - val_accuracy: 0.9596\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1179 - accuracy: 0.9693 - val_loss: 0.1273 - val_accuracy: 0.9596\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1164 - accuracy: 0.9781 - val_loss: 0.1229 - val_accuracy: 0.9596\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1156 - accuracy: 0.9781 - val_loss: 0.1301 - val_accuracy: 0.9697\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.1213 - val_accuracy: 0.9596\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1103 - accuracy: 0.9781 - val_loss: 0.1185 - val_accuracy: 0.9596\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1098 - accuracy: 0.9737 - val_loss: 0.1166 - val_accuracy: 0.9596\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1077 - accuracy: 0.9737 - val_loss: 0.1245 - val_accuracy: 0.9596\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1078 - accuracy: 0.9781 - val_loss: 0.1168 - val_accuracy: 0.9596\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1074 - accuracy: 0.9781 - val_loss: 0.1168 - val_accuracy: 0.9697\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1095 - accuracy: 0.9649 - val_loss: 0.1133 - val_accuracy: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb5947790>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo con funcion activacion SELU\n",
    "modelo4 = Sequential()\n",
    "modelo4.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo4.add(Dense(units=13, activation='selu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo4.add(Dense(units=12, activation= 'selu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo4.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo4.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo4.fit(X_val_train,y_val_train,validation_split=0.3, epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5b73de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 2s 37ms/step - loss: 0.8357 - accuracy: 0.3602 - val_loss: 0.7399 - val_accuracy: 0.3636\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.6461 - accuracy: 0.5287 - val_loss: 0.6020 - val_accuracy: 0.6515\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.5313 - accuracy: 0.7931 - val_loss: 0.5036 - val_accuracy: 0.8939\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.8851 - val_loss: 0.4544 - val_accuracy: 0.9091\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3930 - accuracy: 0.9195 - val_loss: 0.3987 - val_accuracy: 0.9091\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3471 - accuracy: 0.9234 - val_loss: 0.3643 - val_accuracy: 0.9242\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3135 - accuracy: 0.9310 - val_loss: 0.3311 - val_accuracy: 0.9242\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.2875 - accuracy: 0.9387 - val_loss: 0.3081 - val_accuracy: 0.9394\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.2654 - accuracy: 0.9387 - val_loss: 0.2929 - val_accuracy: 0.9394\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.2474 - accuracy: 0.9464 - val_loss: 0.2833 - val_accuracy: 0.9242\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.2343 - accuracy: 0.9502 - val_loss: 0.2617 - val_accuracy: 0.9394\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2225 - accuracy: 0.9425 - val_loss: 0.2547 - val_accuracy: 0.9394\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2137 - accuracy: 0.9464 - val_loss: 0.2425 - val_accuracy: 0.9394\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2048 - accuracy: 0.9425 - val_loss: 0.2326 - val_accuracy: 0.9394\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1961 - accuracy: 0.9425 - val_loss: 0.2237 - val_accuracy: 0.9394\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1890 - accuracy: 0.9502 - val_loss: 0.2161 - val_accuracy: 0.9394\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1843 - accuracy: 0.9425 - val_loss: 0.2088 - val_accuracy: 0.9394\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1789 - accuracy: 0.9464 - val_loss: 0.2021 - val_accuracy: 0.9394\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1722 - accuracy: 0.9540 - val_loss: 0.1954 - val_accuracy: 0.9394\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1684 - accuracy: 0.9540 - val_loss: 0.1900 - val_accuracy: 0.9394\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1640 - accuracy: 0.9579 - val_loss: 0.1902 - val_accuracy: 0.9394\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1599 - accuracy: 0.9540 - val_loss: 0.1806 - val_accuracy: 0.9394\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1564 - accuracy: 0.9579 - val_loss: 0.1841 - val_accuracy: 0.9545\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1544 - accuracy: 0.9540 - val_loss: 0.1744 - val_accuracy: 0.9545\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1502 - accuracy: 0.9617 - val_loss: 0.1682 - val_accuracy: 0.9394\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1477 - accuracy: 0.9540 - val_loss: 0.1703 - val_accuracy: 0.9545\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1435 - accuracy: 0.9617 - val_loss: 0.1624 - val_accuracy: 0.9545\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1442 - accuracy: 0.9502 - val_loss: 0.1622 - val_accuracy: 0.9545\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.1402 - accuracy: 0.9579 - val_loss: 0.1614 - val_accuracy: 0.9545\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.1378 - accuracy: 0.9579 - val_loss: 0.1585 - val_accuracy: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb6cacd30>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo con funcion activacion softplus\n",
    "modelo5 = Sequential()\n",
    "modelo5.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo5.add(Dense(units=13, activation='softplus',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo5.add(Dense(units=12, activation= 'softplus',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo5.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo5.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo5.fit(X_val_train,y_val_train,validation_split=0.2, epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ba130d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 5s 12ms/step - loss: 0.5200 - accuracy: 0.7506\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.2743 - accuracy: 0.9153\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.2062 - accuracy: 0.9451 0s - loss: 0.2210 - accuracy: 0.\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1762 - accuracy: 0.9542\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.1559 - accuracy: 0.9588\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.1446 - accuracy: 0.9657\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.1366 - accuracy: 0.9680\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.1284 - accuracy: 0.9703\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.1281 - accuracy: 0.9657\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1210 - accuracy: 0.9657\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.1150 - accuracy: 0.9680\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1138 - accuracy: 0.9680\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1103 - accuracy: 0.9703\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1068 - accuracy: 0.9725 0s - loss: 0.1069 - accuracy: 0.97\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.1054 - accuracy: 0.9725\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9680\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1021 - accuracy: 0.9680\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0996 - accuracy: 0.9703\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0983 - accuracy: 0.9748 0s - loss: 0.1107 - accuracy\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.0978 - accuracy: 0.9703\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0964 - accuracy: 0.9634\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 0.0948 - accuracy: 0.9680\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0935 - accuracy: 0.9680\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0930 - accuracy: 0.9703\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0920 - accuracy: 0.9703\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.0901 - accuracy: 0.9703 0s - loss: 0.0883 - accuracy: 0.\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0896 - accuracy: 0.9725\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0883 - accuracy: 0.9680\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0887 - accuracy: 0.9748\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0864 - accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb70d94c0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluacion de modelo con funcion activacion SELU con el train\n",
    "modelo6 = Sequential()\n",
    "modelo6.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modelo6.add(Dense(units=13, activation='selu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo6.add(Dense(units=12, activation= 'selu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo6.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modelo6.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modelo6.fit(X_train,y_train,validation_split=0., epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "74e9630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "37/37 [==============================] - 2s 14ms/step - loss: 0.4568 - accuracy: 0.8148\n",
      "Epoch 2/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.2323 - accuracy: 0.9348\n",
      "Epoch 3/30\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.1783 - accuracy: 0.9503\n",
      "Epoch 4/30\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.1506 - accuracy: 0.9571\n",
      "Epoch 5/30\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1326 - accuracy: 0.9605\n",
      "Epoch 6/30\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.1245 - accuracy: 0.9640\n",
      "Epoch 7/30\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.1182 - accuracy: 0.9640\n",
      "Epoch 8/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1115 - accuracy: 0.9674\n",
      "Epoch 9/30\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1070 - accuracy: 0.9708\n",
      "Epoch 10/30\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1046 - accuracy: 0.9657\n",
      "Epoch 11/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1020 - accuracy: 0.9657\n",
      "Epoch 12/30\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.1001 - accuracy: 0.9640\n",
      "Epoch 13/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0967 - accuracy: 0.9674\n",
      "Epoch 14/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0934 - accuracy: 0.9640\n",
      "Epoch 15/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0917 - accuracy: 0.9657\n",
      "Epoch 16/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0876 - accuracy: 0.9743\n",
      "Epoch 17/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0905 - accuracy: 0.9674\n",
      "Epoch 18/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0892 - accuracy: 0.9657\n",
      "Epoch 19/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0857 - accuracy: 0.9674\n",
      "Epoch 20/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.9640\n",
      "Epoch 21/30\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0839 - accuracy: 0.9726\n",
      "Epoch 22/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0812 - accuracy: 0.9726\n",
      "Epoch 23/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0807 - accuracy: 0.9691\n",
      "Epoch 24/30\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0817 - accuracy: 0.9691\n",
      "Epoch 25/30\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0784 - accuracy: 0.9726\n",
      "Epoch 26/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0803 - accuracy: 0.9726\n",
      "Epoch 27/30\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.0783 - accuracy: 0.9674\n",
      "Epoch 28/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0787 - accuracy: 0.9708\n",
      "Epoch 29/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0775 - accuracy: 0.9726\n",
      "Epoch 30/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0769 - accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb3d37850>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloF = Sequential()\n",
    "modeloF.add(Input(shape=(9,), name= \"Entrada\"))\n",
    "modeloF.add(Dense(units=13, activation='selu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modeloF.add(Dense(units=12, activation= 'selu',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modeloF.add(Dense(units=1, activation= 'sigmoid',kernel_initializer=initializers.glorot_uniform(seed=123)))\n",
    "modeloF.compile(loss= 'binary_crossentropy' , optimizer= 'sgd' , metrics=[ 'accuracy' ])\n",
    "modeloF.fit(X,y, epochs=30,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6c16e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump thickness</th>\n",
       "      <th>Unif_Cell_Size</th>\n",
       "      <th>Unif_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatine</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.23</td>\n",
       "      <td>9.17</td>\n",
       "      <td>9.57</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.79</td>\n",
       "      <td>1.45</td>\n",
       "      <td>9.24</td>\n",
       "      <td>9.94</td>\n",
       "      <td>9.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.47</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.82</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3.45</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.24</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.64</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.02</td>\n",
       "      <td>9.56</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.80</td>\n",
       "      <td>2.45</td>\n",
       "      <td>7.79</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.53</td>\n",
       "      <td>8.57</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.82</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Clump thickness  Unif_Cell_Size  Unif_Cell_Shape  Marginal_Adhesion  \\\n",
       "0              4.23            9.17             9.57               9.85   \n",
       "1              0.19            0.93             0.51               0.82   \n",
       "2              4.47            0.09             0.01               0.14   \n",
       "3              2.82            0.34             0.03               0.29   \n",
       "4              0.76            0.05             0.43               0.85   \n",
       "..              ...             ...              ...                ...   \n",
       "95             3.45            0.11             3.93               0.79   \n",
       "96             2.24            0.52             0.06               0.66   \n",
       "97             4.64            2.59             4.29               4.05   \n",
       "98             7.80            2.45             7.79               2.44   \n",
       "99             5.82            0.33             0.51               2.26   \n",
       "\n",
       "    Single_Cell_Size  Bare_Nuclei  Bland_Chromatine  Normal_Nucleoli  Mitoses  \n",
       "0               9.79         1.45              9.24             9.94     9.12  \n",
       "1               1.35         0.11              0.48             0.66     0.64  \n",
       "2               1.60         0.22              1.90             0.68     0.76  \n",
       "3               1.29         0.40              1.53             0.22     0.82  \n",
       "4               1.58         0.40              0.39             0.00     0.62  \n",
       "..               ...          ...               ...              ...      ...  \n",
       "95              1.69         0.35              0.57             0.00     0.34  \n",
       "96              1.23         0.58              2.97             0.53     0.26  \n",
       "97              2.67         2.69              3.02             9.56     0.83  \n",
       "98              3.53         8.57              7.46             8.10     7.65  \n",
       "99              1.31         0.06              0.76             0.31     0.55  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pronostico de nuevas observaciones con modelo4 con mejor accuracy\n",
    "df1 = pd.read_csv('X_para_evaluar.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c436904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3909010e-05],\n",
       "       [9.8797065e-01],\n",
       "       [9.8588330e-01],\n",
       "       [9.9230933e-01],\n",
       "       [9.9387252e-01],\n",
       "       [1.4359742e-01],\n",
       "       [4.7343681e-05],\n",
       "       [9.9452519e-01],\n",
       "       [9.9061978e-01],\n",
       "       [4.7609361e-04],\n",
       "       [9.9430990e-01],\n",
       "       [9.9034178e-01],\n",
       "       [1.2956700e-02],\n",
       "       [1.1673233e-03],\n",
       "       [9.9091142e-01],\n",
       "       [9.9004561e-01],\n",
       "       [9.8502141e-01],\n",
       "       [2.1002482e-04],\n",
       "       [4.3928392e-02],\n",
       "       [9.9148411e-01],\n",
       "       [3.4161730e-04],\n",
       "       [9.8625791e-01],\n",
       "       [9.8234689e-01],\n",
       "       [9.8875844e-01],\n",
       "       [9.5919961e-01],\n",
       "       [9.9045616e-01],\n",
       "       [9.9241638e-01],\n",
       "       [9.8236805e-01],\n",
       "       [9.9355185e-01],\n",
       "       [3.2053562e-05],\n",
       "       [9.9061918e-01],\n",
       "       [9.8705298e-01],\n",
       "       [9.9164057e-01],\n",
       "       [5.8646772e-05],\n",
       "       [7.2425772e-03],\n",
       "       [9.9447733e-01],\n",
       "       [9.8837924e-01],\n",
       "       [9.6944594e-01],\n",
       "       [1.5195286e-01],\n",
       "       [9.9057359e-01],\n",
       "       [9.9280554e-01],\n",
       "       [2.6869049e-04],\n",
       "       [9.8940641e-01],\n",
       "       [9.8816329e-01],\n",
       "       [9.8183918e-01],\n",
       "       [9.8180103e-01],\n",
       "       [2.5718164e-02],\n",
       "       [9.9185783e-01],\n",
       "       [7.7013881e-03],\n",
       "       [9.9417204e-01],\n",
       "       [9.9377394e-01],\n",
       "       [9.5380908e-01],\n",
       "       [9.7939759e-01],\n",
       "       [9.7286588e-01],\n",
       "       [2.3939746e-02],\n",
       "       [1.4134730e-05],\n",
       "       [4.8827101e-03],\n",
       "       [9.7926545e-01],\n",
       "       [2.8058391e-03],\n",
       "       [1.2713823e-02],\n",
       "       [1.4679638e-01],\n",
       "       [5.1683977e-02],\n",
       "       [3.2631474e-04],\n",
       "       [9.8778790e-01],\n",
       "       [9.9195635e-01],\n",
       "       [4.1998341e-03],\n",
       "       [9.4479233e-01],\n",
       "       [9.8989505e-01],\n",
       "       [2.9796239e-02],\n",
       "       [1.1593179e-01],\n",
       "       [9.9415600e-01],\n",
       "       [9.7909319e-01],\n",
       "       [9.9295068e-01],\n",
       "       [9.9471140e-01],\n",
       "       [6.5627322e-03],\n",
       "       [6.8848312e-02],\n",
       "       [9.9350643e-01],\n",
       "       [4.1694954e-04],\n",
       "       [9.6169990e-01],\n",
       "       [1.4309407e-03],\n",
       "       [9.9331301e-01],\n",
       "       [3.0512239e-05],\n",
       "       [3.7843690e-04],\n",
       "       [9.8354381e-01],\n",
       "       [9.5592922e-01],\n",
       "       [4.0653966e-05],\n",
       "       [1.4203446e-04],\n",
       "       [9.8813105e-01],\n",
       "       [1.5745616e-02],\n",
       "       [9.9420762e-01],\n",
       "       [9.8060167e-01],\n",
       "       [9.8159087e-01],\n",
       "       [9.9104345e-01],\n",
       "       [9.8640531e-01],\n",
       "       [9.9281448e-01],\n",
       "       [9.8897946e-01],\n",
       "       [9.9261522e-01],\n",
       "       [1.4088038e-01],\n",
       "       [2.8808946e-03],\n",
       "       [9.7966629e-01]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronosticos_1=modeloF.predict(df1)\n",
    "pronosticos_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7dc68b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronosticos = np.where(pronosticos_1 > 0.5, 0, 1)\n",
    "pronosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c1c14a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = (modeloF.predict(df1) < 0.5).astype(\"int32\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "28e35805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediccion de los nuevos valores \n",
    "y_pred = modeloF.predict(df1)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c08fe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pronosticos).to_csv('Gonzalo_Matos_Montoya_Prediccion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd30977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1cffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b4299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee4a1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo4.save('GonzaloMatosMontoya_Parcial1.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0295975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844622b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f50ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
